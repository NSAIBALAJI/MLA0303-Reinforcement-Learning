import numpy as np
import random
import matplotlib.pyplot as plt
n_rows, n_cols = 3, 3
start_state = (0, 0)
actions = [(0, 1), (0, -1), (1, 0), (-1, 0)]
epsilon = 0.2
state_values = np.zeros((n_rows, n_cols))
max_steps = 100
def choose_action(state):
    if random.uniform(0, 1) < epsilon:
        return random.choice(range(len(actions)))
    else:
        return np.argmax([state_values[np.clip(state[0] + a[0], 0, n_rows - 1), np.clip(state[1] + a[1], 0, n_cols - 1)] for a in actions])
num_episodes = 1000
episode_rewards = []
for _ in range(num_episodes):
    current_state = start_state
    episode_reward = 0
    steps = 0
    while current_state != (2, 2) and steps < max_steps:
        action = choose_action(current_state)
        next_state = (current_state[0] + actions[action][0], current_state[1] + actions[action][1])
        if next_state == (2, 2):
            reward = 1
        else:
            reward = 0
        state_values[np.clip(current_state[0], 0, n_rows - 1), np.clip(current_state[1], 0, n_cols - 1)] += 0.1 * (reward + 0.9 * state_values[np.clip(next_state[0], 0, n_rows - 1), np.clip(next_state[1], 0, n_cols - 1)] - state_values[np.clip(current_state[0], 0, n_rows - 1), np.clip(current_state[1], 0, n_cols - 1)])
        episode_reward += reward
        current_state = next_state
        steps += 1
    episode_rewards.append(episode_reward)
plt.plot(episode_rewards)
plt.xlabel('Episode')
plt.ylabel('Cumulative Reward')
plt.title('Exploration vs. Exploitation in RL')
plt.show()
